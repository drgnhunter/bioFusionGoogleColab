{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drgnhunter/bioFusionGoogleColab/blob/main/biofusionV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C026o5dEGxT8"
      },
      "outputs": [],
      "source": [
        "pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaCge3ihGxT9"
      },
      "outputs": [],
      "source": [
        "pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "id": "A13rEGSCGxT9"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nRIHkmpYGxT9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069c0c5a-2114-4e40-f2dc-85673bae9b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JhitLhPnGxT9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f1ef8e01-010b-46f7-8842-ed82ba3a712e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'chest_xray/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2121547151.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Use the paths confirmed by your os.walk loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chest_xray/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chest_xray/train'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Preprocessing: resized to 224x224 as required for most CNNs\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(), # Augmentation to prevent overfitting\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Use the paths confirmed by your os.walk loop\n",
        "train_dataset = datasets.ImageFolder('chest_xray/train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Validation set as required by the \"Validation Approach\" criteria\n",
        "val_dataset = datasets.ImageFolder('chest_xray/val', transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8qgVzjP74-Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0Uhrw4cGxT9"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MedicalCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MedicalCNN, self).__init__()\n",
        "        # Soundness and originality of architecture\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 28 * 28, 128), nn.ReLU(),\n",
        "            nn.Dropout(0.5), # Prevents overfitting\n",
        "            nn.Linear(128, 1), nn.Sigmoid() # Binary output for Normal vs Pneumonia\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "model = MedicalCNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLBeEN7nGxT-"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Hyperparameter choice\n",
        "criterion = nn.BCELoss() # Loss computation\n",
        "\n",
        "for epoch in range(15):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        # 1. Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "\n",
        "        # 2. Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # 3. Optimizer update\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiM5ne_aGxT-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define the file name based on your team name as per submission conventions\n",
        "model_save_path = \"pneumoniaDetectorModel.pth\"\n",
        "\n",
        "# Save the model state_dict (weights)\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model successfully saved to {model_save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoaRojhSGxT-"
      },
      "outputs": [],
      "source": [
        "pip install scikit-learn seaborn matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTWFEcdDGxT-"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Preprocessing for testing (must match training resize/normalization) [cite: 89, 161]\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Loading the test set [cite: 126]\n",
        "# Note: Use the path confirmed in your directory: 'chest_xray/test'\n",
        "test_dataset = datasets.ImageFolder('chest_xray/test', transform=test_transform)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Test loader defined with {len(test_dataset)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chgeWDh0GxT-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval() # Set model to evaluation mode\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for testing\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        # Convert probabilities to binary predictions (0 or 1)\n",
        "        preds = (outputs > 0.5).float()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Detailed Classification Report (Precision, Recall, F1-Score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Normal', 'Pneumonia']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1eZjSU6GxT-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval() # Set to evaluation mode (freezes BatchNorm and Dropout) [cite: 125, 220]\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend(predictions.reshape(-1).tolist())\n",
        "\n",
        "# 1. Primary & Secondary Metrics [cite: 135, 136]\n",
        "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
        "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))\n",
        "\n",
        "# 2. Mandatory Confusion Matrix [cite: 137]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'])\n",
        "plt.title('Confusion Matrix - Pneumonia Detection Model')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p6c70jNGxT_"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. ADVANCED DATA AUGMENTATION (Training Set Only) [cite: 89, 208]\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    # Randomly rotate images by 15 degrees to simulate different X-ray angles\n",
        "    transforms.RandomRotation(15),\n",
        "    # Randomly zoom and crop to focus on different lung areas\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    # Randomly flip images horizontally\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # Adjust brightness and contrast to simulate different X-ray exposures\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    # Standard normalization for medical imaging [cite: 161]\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 2. STANDARD PREPROCESSING (Validation/Test Sets) [cite: 161]\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Loading datasets using the updated transforms [cite: 126]\n",
        "train_dataset = datasets.ImageFolder('chest_xray/train', transform=train_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = datasets.ImageFolder('chest_xray/val', transform=test_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = datasets.ImageFolder('chest_xray/test', transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eWjNfEyeGxT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de90cf9-207d-4b61-969a-f136a1f1b219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval() # Set to evaluation mode (freezes BatchNorm and Dropout) [cite: 125, 220]\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend(predictions.reshape(-1).tolist())\n",
        "\n",
        "# 1. Primary & Secondary Metrics [cite: 135, 136]\n",
        "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
        "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))\n",
        "\n",
        "# 2. Mandatory Confusion Matrix [cite: 137]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'])\n",
        "plt.title('Confusion Matrix - Pneumonia Detection Model')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "gWpEt_F4I8Li",
        "outputId": "c77341fa-a8b0-4bd5-d601-4933c5abc23a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[0;32m      2\u001b[0m files\u001b[38;5;241m.\u001b[39mupload()\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle # creating .kaggle folder where the key should be placed\n"
      ],
      "metadata": {
        "id": "-iqDYLzCKIbb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/ # move the key to the folder\n"
      ],
      "metadata": {
        "id": "w6vNkp4GKJlz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd # checking the present working directory\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KSsbpQqKNPL",
        "outputId": "00f382ae-7738-46a1-8519-e7570ba00c42"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "6KG3IpaHKSMb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlHHiQXCKWJ1",
        "outputId": "f9f7ea07-064a-490e-f6a1-693520de7e63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                     title                                           size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------  ----------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "neurocipher/heartdisease                                Heart Disease                                   3491  2025-12-11 15:29:14.327000           2114        167  1.0              \n",
            "neurocipher/student-performance                         Student Performance                            49705  2025-12-12 12:06:28.973000           1261        105  1.0              \n",
            "dansbecker/powerlifting-database                        powerlifting-database                        9277600  2019-04-30 21:07:41.560000          24255        351  0.5882353        \n",
            "rtatman/188-million-us-wildfires                        1.88 Million US Wildfires                  176270559  2020-05-12 21:03:49.213000          41816       1406  0.8235294        \n",
            "residentmario/ramen-ratings                             Ramen Ratings                                  40762  2018-01-11 16:04:39.893000          54264        965  0.7058824        \n",
            "nolanbconaway/pitchfork-data                            18,393 Pitchfork Reviews                    34891456  2017-01-13 04:18:10.113000          16956        444  0.7058824        \n",
            "jpmiller/publicassistance                               US Public Food Assistance 1 - WIC             304041  2023-04-17 20:01:05.960000          24802        498  0.9411765        \n",
            "residentmario/things-on-reddit                          Things on Reddit                            16773230  2017-10-26 14:10:15.157000          14697        307  0.5882353        \n",
            "nasa/kepler-exoplanet-search-results                    Kepler Exoplanet Search Results              1215549  2017-10-10 18:26:59.497000          21070        837  0.8235294        \n",
            "dansbecker/melbourne-housing-snapshot                   Melbourne Housing Snapshot                    461423  2018-06-05 12:52:24.087000         200095       1719  0.7058824        \n",
            "datasnaek/youtube-new                                   Trending YouTube Video Statistics          210575746  2019-06-03 00:56:47.177000         292850       5838  0.7941176        \n",
            "zynicide/wine-reviews                                   Wine Reviews                                53336293  2017-11-27 17:08:04.700000         343808       3816  0.7941176        \n",
            "datasnaek/chess                                         Chess Game Dataset (Lichess)                 2903760  2017-09-04 03:09:09.453000          60913       1433  0.8235294        \n",
            "suvidyasonawane/student-performance-dataset             Student Performance Dataset                    81679  2025-12-25 05:27:51.453000              0         44  1.0              \n",
            "wardabilal/spotify-global-music-dataset-20092025        Spotify Global Music Dataset (2009â€“2025)     1289021  2025-11-11 09:43:05.933000          16387        469  1.0              \n",
            "kundanbedmutha/exam-score-prediction-dataset            Exam Score Prediction Dataset                 325454  2025-11-28 07:29:01.047000           5863        208  1.0              \n",
            "iabhishekofficial/mobile-price-classification           Mobile Price Classification                    72340  2018-01-28 08:44:24.237000         246146       2471  0.7058824        \n",
            "ishank2005/wind-turbines-data-csv                       Turbines_Data.csv                             119226  2025-12-30 04:49:19.717000              0         22  1.0              \n",
            "dansbecker/home-data-for-ml-course                      home data for ml course                        96211  2019-01-23 00:45:18.757000          26325        296  0.3529412        \n",
            "sergiykovalchuck/the-most-popular-books-for-exchanging  The Most Popular Books for Exchanging          89220  2025-12-05 12:53:35.100000             90         25  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJLxUXLDKcDt",
        "outputId": "4dfba343-5e35-4c03-fd0b-b05177dce123"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            " 99% 2.28G/2.29G [00:34<00:00, 219MB/s]\n",
            "100% 2.29G/2.29G [00:34<00:00, 71.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q chest-xray-pneumonia.zip -d ."
      ],
      "metadata": {
        "id": "lj6OVYm1MDyY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "id": "qTghK8u4MYdR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Preprocessing: resized to 224x224 as required for most CNNs\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(), # Augmentation to prevent overfitting\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Use the paths confirmed by your os.walk loop\n",
        "train_dataset = datasets.ImageFolder('chest_xray/train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Validation set as required by the \"Validation Approach\" criteria\n",
        "val_dataset = datasets.ImageFolder('chest_xray/val', transform=transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "STqoHg2CMafp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MedicalCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MedicalCNN, self).__init__()\n",
        "        # Soundness and originality of architecture\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 28 * 28, 128), nn.ReLU(),\n",
        "            nn.Dropout(0.5), # Prevents overfitting\n",
        "            nn.Linear(128, 1), nn.Sigmoid() # Binary output for Normal vs Pneumonia\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "model = MedicalCNN()"
      ],
      "metadata": {
        "id": "-grGMu9jMghC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Hyperparameter choice\n",
        "criterion = nn.BCELoss() # Loss computation\n",
        "\n",
        "for epoch in range(15):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        # 1. Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "\n",
        "        # 2. Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # 3. Optimizer update\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So2oCuatMjJL",
        "outputId": "52952980-7323-4142-fe04-c9b2b9db2529"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 complete.\n",
            "Epoch 2 complete.\n",
            "Epoch 3 complete.\n",
            "Epoch 4 complete.\n",
            "Epoch 5 complete.\n",
            "Epoch 6 complete.\n",
            "Epoch 7 complete.\n",
            "Epoch 8 complete.\n",
            "Epoch 9 complete.\n",
            "Epoch 10 complete.\n",
            "Epoch 11 complete.\n",
            "Epoch 12 complete.\n",
            "Epoch 13 complete.\n",
            "Epoch 14 complete.\n",
            "Epoch 15 complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the file name based on your team name as per submission conventions\n",
        "model_save_path = \"pneumoniaDetectorModelv1.pth\"\n",
        "\n",
        "# Save the model state_dict (weights)\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model successfully saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa85rfGMW7FW",
        "outputId": "9cb6dea1-2e5f-43ca-c68c-45776b08b3e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved to pneumoniaDetectorModelv1.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn seaborn matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZn9aOkVW-Nl",
        "outputId": "0c4722c4-5913-4803-f1c0-01f979a5ea76"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\python311\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in c:\\python311\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in c:\\python311\\lib\\site-packages (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\python311\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\python311\\lib\\site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\python311\\lib\\site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\python311\\lib\\site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (C:\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (C:\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ip (C:\\Python311\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~umpy (C:\\Python311\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Preprocessing for testing (must match training resize/normalization) [cite: 89, 161]\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Loading the test set [cite: 126]\n",
        "# Note: Use the path confirmed in your directory: 'chest_xray/test'\n",
        "test_dataset = datasets.ImageFolder('chest_xray/test', transform=test_transform)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Test loader defined with {len(test_dataset)} images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOPSlh7IXBae",
        "outputId": "725ac0a9-40c9-4024-f2ed-2a19afa1e2c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loader defined with 624 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval() # Set model to evaluation mode\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for testing\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        # Convert probabilities to binary predictions (0 or 1)\n",
        "        preds = (outputs > 0.5).float()\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Detailed Classification Report (Precision, Recall, F1-Score)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=['Normal', 'Pneumonia']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgXtoxqKXEne",
        "outputId": "1f96d1cf-6447-4b6c-ddad-23d3385511fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.04%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      0.31      0.47       234\n",
            "   Pneumonia       0.71      1.00      0.83       390\n",
            "\n",
            "    accuracy                           0.74       624\n",
            "   macro avg       0.85      0.65      0.65       624\n",
            "weighted avg       0.81      0.74      0.70       624\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval() # Set to evaluation mode (freezes BatchNorm and Dropout) [cite: 125, 220]\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        predictions = (outputs > 0.5).float()\n",
        "\n",
        "        y_true.extend(labels.tolist())\n",
        "        y_pred.extend(predictions.reshape(-1).tolist())\n",
        "\n",
        "# 1. Primary & Secondary Metrics [cite: 135, 136]\n",
        "print(f\"Test Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
        "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred, target_names=['Normal', 'Pneumonia']))\n",
        "\n",
        "# 2. Mandatory Confusion Matrix [cite: 137]\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Normal', 'Pneumonia'],\n",
        "            yticklabels=['Normal', 'Pneumonia'])\n",
        "plt.title('Confusion Matrix - Pneumonia Detection Model')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "YmHhUOIyXX_X",
        "outputId": "3bd75055-9a76-4f73-f617-a9c963e6d4b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 74.04%\n",
            "\n",
            "Detailed Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.99      0.31      0.47       234\n",
            "   Pneumonia       0.71      1.00      0.83       390\n",
            "\n",
            "    accuracy                           0.74       624\n",
            "   macro avg       0.85      0.65      0.65       624\n",
            "weighted avg       0.81      0.74      0.70       624\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Training transforms with Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Test transforms (No Augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_loader = DataLoader(datasets.ImageFolder('chest_xray/train', transform=train_transform), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(datasets.ImageFolder('chest_xray/test', transform=test_transform), batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "sEhJJbs1YODy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Training transforms with Augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Test transforms (No Augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_loader = DataLoader(datasets.ImageFolder('chest_xray/train', transform=train_transform), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(datasets.ImageFolder('chest_xray/test', transform=test_transform), batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "3OSaVi28Y0Mc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MedicalCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MedicalCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 28 * 28, 128), nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 1) # Outputting logits for BCEWithLogitsLoss\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.features(x))\n",
        "\n",
        "model = MedicalCNN()"
      ],
      "metadata": {
        "id": "C48rM24sZRFO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# pos_weight < 1 makes the model more 'conservative' about predicting Pneumonia\n",
        "# This specifically targets your low Normal recall\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([0.7]).to(device))\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Scheduler reduces LR by half if validation loss doesn't improve for 3 epochs\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "for epoch in range(25): # Increased epochs for stabilization\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Placeholder for validation loss check to step the scheduler\n",
        "    # scheduler.step(val_loss)\n",
        "    print(f\"Epoch {epoch+1} | Loss: {train_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo_GaVEAZrrX",
        "outputId": "b335ec4b-9ed5-46ea-ad4a-f65c67dd31a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 0.4796\n",
            "Epoch 2 | Loss: 0.2155\n",
            "Epoch 3 | Loss: 0.2057\n",
            "Epoch 4 | Loss: 0.1846\n",
            "Epoch 5 | Loss: 0.1737\n",
            "Epoch 6 | Loss: 0.1694\n",
            "Epoch 7 | Loss: 0.1684\n",
            "Epoch 8 | Loss: 0.1669\n",
            "Epoch 9 | Loss: 0.1506\n",
            "Epoch 10 | Loss: 0.1533\n",
            "Epoch 11 | Loss: 0.1518\n",
            "Epoch 12 | Loss: 0.1428\n",
            "Epoch 13 | Loss: 0.1442\n",
            "Epoch 14 | Loss: 0.1585\n",
            "Epoch 15 | Loss: 0.1431\n",
            "Epoch 16 | Loss: 0.1460\n",
            "Epoch 17 | Loss: 0.1356\n",
            "Epoch 18 | Loss: 0.1348\n",
            "Epoch 19 | Loss: 0.1307\n",
            "Epoch 20 | Loss: 0.1325\n",
            "Epoch 21 | Loss: 0.1280\n",
            "Epoch 22 | Loss: 0.1299\n",
            "Epoch 23 | Loss: 0.1330\n",
            "Epoch 24 | Loss: 0.1247\n",
            "Epoch 25 | Loss: 0.1219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the file name based on your team name as per submission conventions\n",
        "model_save_path = \"pneumoniaDetectorModelv2.pth\"\n",
        "\n",
        "# Save the model state_dict (weights)\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model successfully saved to {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg3xeGW9pHQD",
        "outputId": "6dc2569b-cbc7-4af3-aa55-6446e475a5e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model successfully saved to pneumoniaDetectorModelv2.pth\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 17810,
          "sourceId": 23812,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}